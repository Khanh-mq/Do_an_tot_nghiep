{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41221a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Đã lưu 361 speech pairs vào ./fleurs_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "# Config language và split\n",
    "src_lang = \"en_us\"\n",
    "tgt_lang = \"vi_vn\"   # English (US)\n",
    "split = \"validation\"  # Đổi thành \"train\" khi muốn full\n",
    "\n",
    "# Load dataset\n",
    "src_dataset = load_dataset(\"google/fleurs\", src_lang, split=split)\n",
    "tgt_dataset = load_dataset(\"google/fleurs\", tgt_lang, split=split)\n",
    "\n",
    "# Thư mục lưu\n",
    "data_dir = \"./fleurs_data\"\n",
    "src_dir = os.path.join(data_dir, \"src\")\n",
    "tgt_dir = os.path.join(data_dir, \"tgt\")\n",
    "os.makedirs(src_dir, exist_ok=True)\n",
    "os.makedirs(tgt_dir, exist_ok=True)\n",
    "\n",
    "# Lưu audio (16kHz sẵn)\n",
    "for i in range(min(len(src_dataset), len(tgt_dataset))):\n",
    "    # Source (Punjabi)\n",
    "    audio_src = src_dataset[i][\"audio\"][\"array\"]\n",
    "    sr = src_dataset[i][\"audio\"][\"sampling_rate\"]  # 16000\n",
    "    src_path = os.path.join(src_dir, f\"{i:06d}.wav\")\n",
    "    sf.write(src_path, audio_src, sr)\n",
    "\n",
    "    # Target (English)\n",
    "    audio_tgt = tgt_dataset[i][\"audio\"][\"array\"]\n",
    "    tgt_path = os.path.join(tgt_dir, f\"{i:06d}.wav\")\n",
    "    sf.write(tgt_path, audio_tgt, sr)\n",
    "\n",
    "print(f\"Done! Đã lưu {min(len(src_dataset), len(tgt_dataset))} speech pairs vào {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd87202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnaifest tạo xong: ./fleurs_data/validation.src.tsv và ./fleurs_data/validation.tgt.tsv\n"
     ]
    }
   ],
   "source": [
    "src_manifest = os.path.join(data_dir, f\"{split}.src.tsv\")\n",
    "tgt_manifest = os.path.join(data_dir, f\"{split}.tgt.tsv\")\n",
    "\n",
    "with open(src_manifest, \"w\") as f_src, open(tgt_manifest, \"w\") as f_tgt:\n",
    "    f_src.write(src_dir + \"\\n\")\n",
    "    f_tgt.write(tgt_dir + \"\\n\")\n",
    "\n",
    "    for i in range(min(len(src_dataset), len(tgt_dataset))):\n",
    "        filename = f\"{i:06d}.wav\"\n",
    "\n",
    "        # Source\n",
    "        n_samples_src = len(src_dataset[i][\"audio\"][\"array\"])\n",
    "        f_src.write(f\"{filename}\\t{n_samples_src}\\n\")\n",
    "\n",
    "        # Target\n",
    "        n_samples_tgt = len(tgt_dataset[i][\"audio\"][\"array\"])\n",
    "        f_tgt.write(f\"{filename}\\t{n_samples_tgt}\\n\")\n",
    "\n",
    "print(f\"mnaifest tạo xong: {src_manifest} và {tgt_manifest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ca302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_v', 'encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting features để train kmeans...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:56<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 214616\n",
      "Training kmeans...\n",
      "kmeans saved!\n",
      "Inferring units cho từng file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:59<00:00,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit extraction xong! Manifest: ./fleurs_data/train.tgt.unit.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from transformers import HubertModel, Wav2Vec2FeatureExtractor\n",
    "import torchaudio\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Config\n",
    "data_dir = \"./fleurs_data\"\n",
    "tgt_dir = os.path.join(data_dir, \"tgt\")\n",
    "unit_dir = os.path.join(data_dir, \"unit\")\n",
    "os.makedirs(unit_dir, exist_ok=True)\n",
    "split = \"train\"          # Dùng train để train kmeans\n",
    "k_clusters = 1000        # Standard cho English\n",
    "\n",
    "# Load HuBERT\n",
    "model = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "model.eval()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "def extract_features(audio_array):\n",
    "    inputs = feature_extractor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    # Layer 9 (standard cho discrete units)\n",
    "    hidden = outputs.hidden_states[9].squeeze(0).cpu().numpy()  # (time, dim)\n",
    "    return hidden\n",
    "\n",
    "# === 1. Collect features từ target train để train kmeans ===\n",
    "print(\"Collecting features để train kmeans...\")\n",
    "all_features = []\n",
    "for filename in tqdm(sorted(os.listdir(tgt_dir))):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        waveform, sr = torchaudio.load(os.path.join(tgt_dir, filename))\n",
    "        audio = waveform.squeeze(0).numpy()\n",
    "        feats = extract_features(audio)\n",
    "        all_features.append(feats)\n",
    "\n",
    "all_features = np.concatenate(all_features, axis=0)\n",
    "print(f\"Total frames: {all_features.shape[0]}\")\n",
    "\n",
    "# === 2. Train kmeans ===\n",
    "print(\"Training kmeans...\")\n",
    "kmeans = MiniBatchKMeans(n_clusters=k_clusters, batch_size=10000, random_state=0)\n",
    "kmeans.fit(all_features)\n",
    "joblib.dump(kmeans, os.path.join(data_dir, f\"kmeans_{k_clusters}.joblib\"))\n",
    "print(\"kmeans saved!\")\n",
    "\n",
    "# === 3. Infer units + dedup cho tất cả file target ===\n",
    "def get_dedup_units(audio_array):\n",
    "    feats = extract_features(audio_array)\n",
    "    units = kmeans.predict(feats)\n",
    "    # Deduplicate consecutive same units (như paper)\n",
    "    dedup = [units[0]]\n",
    "    for u in units[1:]:\n",
    "        if u != dedup[-1]:\n",
    "            dedup.append(u)\n",
    "    return dedup\n",
    "\n",
    "print(\"Inferring units cho từng file...\")\n",
    "for filename in tqdm(sorted(os.listdir(tgt_dir))):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        waveform, sr = torchaudio.load(os.path.join(tgt_dir, filename))\n",
    "        audio = waveform.squeeze(0).numpy()\n",
    "        units = get_dedup_units(audio)\n",
    "        unit_path = os.path.join(unit_dir, filename.replace(\".wav\", \".unit\"))\n",
    "        with open(unit_path, \"w\") as f:\n",
    "            f.write(\" \".join(map(str, units)))\n",
    "\n",
    "# === 4. Tạo unit manifest ===\n",
    "unit_manifest = os.path.join(data_dir, f\"{split}.tgt.unit.tsv\")\n",
    "with open(unit_manifest, \"w\") as f:\n",
    "    f.write(os.path.abspath(unit_dir) + \"\\n\")\n",
    "    for filename in sorted(os.listdir(unit_dir)):\n",
    "        if filename.endswith(\".unit\"):\n",
    "            unit_path = os.path.join(unit_dir, filename)\n",
    "            with open(unit_path) as uf:\n",
    "                units = uf.read().strip().split()\n",
    "            n_units = len(units)\n",
    "            wav_name = filename.replace(\".unit\", \".wav\")\n",
    "            f.write(f\"{wav_name}\\t{n_units}\\n\")\n",
    "\n",
    "print(f\"Unit extraction xong! Manifest: {unit_manifest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116e872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation pairs: 361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_v', 'encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring units cho validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:45<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data + units xong!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import HubertModel, Wav2Vec2FeatureExtractor\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load kmeans từ train\n",
    "kmeans = joblib.load(\"./fleurs_data/kmeans_1000.joblib\")\n",
    "# Config validation\n",
    "split = \"validation\"\n",
    "src_lang = \"vi_vn\"\n",
    "tgt_lang = \"en_us\"\n",
    "\n",
    "src_dataset = load_dataset(\"google/fleurs\", src_lang, split=split)\n",
    "tgt_dataset = load_dataset(\"google/fleurs\", tgt_lang, split=split)\n",
    "\n",
    "num_pairs = min(len(src_dataset), len(tgt_dataset))\n",
    "print(f\"Validation pairs: {num_pairs}\")\n",
    "\n",
    "# Thư mục validation\n",
    "val_dir = \"./fleurs_data/validation\"\n",
    "src_val_dir = os.path.join(val_dir, \"src\")\n",
    "tgt_val_dir = os.path.join(val_dir, \"tgt\")\n",
    "unit_val_dir = os.path.join(val_dir, \"unit\")  # Tạm, sau rename\n",
    "os.makedirs(src_val_dir, exist_ok=True)\n",
    "os.makedirs(tgt_val_dir, exist_ok=True)\n",
    "os.makedirs(unit_val_dir, exist_ok=True)\n",
    "\n",
    "# Lưu wav\n",
    "for i in range(num_pairs):\n",
    "    audio_src = src_dataset[i][\"audio\"][\"array\"]\n",
    "    sr = src_dataset[i][\"audio\"][\"sampling_rate\"]\n",
    "    src_path = os.path.join(src_val_dir, f\"{i:06d}.wav\")\n",
    "    sf.write(src_path, audio_src, sr)\n",
    "\n",
    "    audio_tgt = tgt_dataset[i][\"audio\"][\"array\"]\n",
    "    tgt_path = os.path.join(tgt_val_dir, f\"{i:06d}.wav\")\n",
    "    sf.write(tgt_path, audio_tgt, sr)\n",
    "\n",
    "# Load HuBERT để extract features (giống trước)\n",
    "model = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "model.eval()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "def extract_features(audio_array):\n",
    "    inputs = feature_extractor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    hidden = outputs.hidden_states[9].squeeze(0).cpu().numpy()\n",
    "    return hidden\n",
    "\n",
    "def get_dedup_units(audio_array):\n",
    "    feats = extract_features(audio_array)\n",
    "    units = kmeans.predict(feats)\n",
    "    dedup = [units[0]]\n",
    "    for u in units[1:]:\n",
    "        if u != dedup[-1]:\n",
    "            dedup.append(u)\n",
    "    return dedup\n",
    "\n",
    "# Infer units cho validation target\n",
    "print(\"Inferring units cho validation...\")\n",
    "for filename in tqdm(sorted(os.listdir(tgt_val_dir))):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        waveform, sr = torchaudio.load(os.path.join(tgt_val_dir, filename))\n",
    "        audio = waveform.squeeze(0).numpy()\n",
    "        units = get_dedup_units(audio)\n",
    "        unit_path = os.path.join(unit_val_dir, filename.replace(\".wav\", \".unit\"))\n",
    "        with open(unit_path, \"w\") as f:\n",
    "            f.write(\" \".join(map(str, units)))\n",
    "\n",
    "print(\"Validation data + units xong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d13829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Cho train\n",
    "shutil.move(\"./fleurs_data/unit\", \"./fleurs_data/du\")\n",
    "shutil.move(\"./fleurs_data/train.tgt.unit.tsv\", \"./fleurs_data/train.du.tsv\")\n",
    "for f in os.listdir(\"./fleurs_data/du\"):\n",
    "    if f.endswith(\".unit\"):\n",
    "        os.rename(os.path.join(\"./fleurs_data/du\", f), os.path.join(\"./fleurs_data/du\", f.replace(\".unit\", \".du\")))\n",
    "\n",
    "# Cho validation (nếu có)\n",
    "val_du_dir = \"./fleurs_data/validation/du\"\n",
    "val_unit_dir = \"./fleurs_data/validation/unit\"\n",
    "if os.path.exists(val_unit_dir):\n",
    "    shutil.move(val_unit_dir, val_du_dir)\n",
    "    # Tạo validation manifest .du.tsv tương tự bước 4 cũ\n",
    "    val_manifest = \"./fleurs_data/validation/valid.du.tsv\"\n",
    "    with open(val_manifest, \"w\") as f:\n",
    "        f.write(os.path.abspath(val_du_dir) + \"\\n\")\n",
    "        for filename in sorted(os.listdir(val_du_dir)):\n",
    "            if filename.endswith(\".du\"):\n",
    "                with open(os.path.join(val_du_dir, filename)) as uf:\n",
    "                    n_units = len(uf.read().strip().split())\n",
    "                wav_name = filename.replace(\".du\", \".wav\")\n",
    "                f.write(f\"{wav_name}\\t{n_units}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f979704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict tạo xong!\n"
     ]
    }
   ],
   "source": [
    "k_clusters = 500\n",
    "dict_path = \"./fleurs_data/dict.du.txt\"\n",
    "\n",
    "with open(dict_path, \"w\") as f:\n",
    "    for i in range(k_clusters):\n",
    "        f.write(f\"{i} 100000\\n\")  # Fake count cao\n",
    "    f.write(\"<unk> 0\\n\")\n",
    "\n",
    "print(\"Dict tạo xong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb211dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/miniconda3/envs/hubert/bin/python\n",
      "Python 3.10.19\n",
      "2026-01-16 18:13:05 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "0.12.2\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version\n",
    "!python -c \"import fairseq; print(fairseq.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecbd5dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata-bin\u001b[0m/    \u001b[01;34mdu\u001b[0m/                 \u001b[01;34msrc\u001b[0m/  train.du.tsv  validation.src.tsv\n",
      "dict.du.txt  kmeans_1000.joblib  \u001b[01;34mtgt\u001b[0m/  \u001b[01;34mvalidation\u001b[0m/   validation.tgt.tsv\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71d82aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/Projects/KhoaLuan/src/fleurs_data\n"
     ]
    }
   ],
   "source": [
    "cd /home/khanh/Projects/KhoaLuan/src/fleurs_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6092b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp validation.src.tsv train.src.tsv\n",
    "!cp validation.tgt.tsv train.tgt.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5e0e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/Projects/KhoaLuan/fairseq\n"
     ]
    }
   ],
   "source": [
    "cd /home/khanh/Projects/KhoaLuan/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b96a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/Projects/KhoaLuan/src/fleurs_data\n"
     ]
    }
   ],
   "source": [
    "%cd ../src/fleurs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aad30136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/Projects/KhoaLuan/src/fleurs_data\n",
      "lrwxrwxrwx 1 khanh khanh      12 Jan 16 19:11 train.du -> train.du.tsv\n",
      "-rw-rw-r-- 1 khanh khanh    5466 Jan 16 17:58 train.du.tsv\n",
      "lrwxrwxrwx 1 khanh khanh      13 Jan 16 19:11 train.src -> train.src.tsv\n",
      "-rw-rw-r-- 1 khanh khanh    6461 Jan 16 18:32 train.src.tsv\n",
      "lrwxrwxrwx 1 khanh khanh      13 Jan 16 19:11 train.tgt -> train.tgt.tsv\n",
      "-rw-rw-r-- 1 khanh khanh    6494 Jan 16 18:32 train.tgt.tsv\n",
      "drwxrwxr-x 5 khanh khanh    4096 Jan 16 18:03 validation\n",
      "lrwxrwxrwx 1 khanh khanh      18 Jan 16 19:11 validation.src -> validation.src.tsv\n",
      "-rw-rw-r-- 1 khanh khanh    6461 Jan 16 17:53 validation.src.tsv\n",
      "lrwxrwxrwx 1 khanh khanh      18 Jan 16 19:11 validation.tgt -> validation.tgt.tsv\n",
      "-rw-rw-r-- 1 khanh khanh    6494 Jan 16 17:53 validation.tgt.tsv\n"
     ]
    }
   ],
   "source": [
    "# Di chuyển vào thư mục\n",
    "%cd /home/khanh/Projects/KhoaLuan/src/fleurs_data\n",
    "\n",
    "# Tạo symlink (quan trọng nhất!)\n",
    "!ln -sf train.src.tsv train.src\n",
    "!ln -sf validation.src.tsv validation.src\n",
    "\n",
    "# Làm thêm cho target (nên làm luôn)\n",
    "!ln -sf train.du.tsv train.du\n",
    "!ln -sf train.tgt.tsv train.tgt\n",
    "!ln -sf validation.tgt.tsv validation.tgt\n",
    "\n",
    "# Kiểm tra kết quả (phải thấy các link -> .tsv)\n",
    "!ls -l | grep -E \"train|validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c73d7068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/khanh/Projects/KhoaLuan/src/fleurs_data'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "699f8ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-16 19:46:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2026-01-16 19:46:09 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='../fairseq/examples/speech_to_speech', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='speech_to_speech', source_lang=None, target_lang=None, trainpref='fleurs_data/train', validpref='fleurs_data/validation/validtion.src.tsv', testpref=None, align_suffix=None, destdir='fleurs_data/data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict='fleurs_data/dict.du.txt', srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=4, dict_only=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/miniconda3/envs/hubert/bin/fairseq-preprocess\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 389, in cli_main\n",
      "    main(args)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 340, in main\n",
      "    src_dict = _build_dictionary(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 87, in _build_dictionary\n",
      "    return task.build_dictionary(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/tasks/fairseq_task.py\", line 114, in build_dictionary\n",
      "    Dictionary.add_file_to_dictionary(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/dictionary.py\", line 354, in add_file_to_dictionary\n",
      "    offsets = find_offsets(local_file, num_workers)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/file_chunker_utils.py\", line 25, in find_offsets\n",
      "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'fleurs_data/train'\n"
     ]
    }
   ],
   "source": [
    "# Thử bỏ 2 argument không hỗ trợ\n",
    "!cd ~/Projects/KhoaLuan/\n",
    "!fairseq-preprocess \\\n",
    "  --user-dir ../fairseq/examples/speech_to_speech \\\n",
    "  --task speech_to_speech \\\n",
    "  --trainpref fleurs_data/train \\\n",
    "  --validpref fleurs_data/validation/validtion.src.tsv \\\n",
    "  --destdir fleurs_data/data-bin \\\n",
    "  --tgtdict fleurs_data/dict.du.txt \\\n",
    "  --workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "494b760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/Projects/KhoaLuan/src\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e1c75b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/Projects/KhoaLuan/src\n",
      "2026-01-16 19:47:24 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2026-01-16 19:47:24 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='../fairseq/examples/speech_to_speech', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='speech_to_speech', source_lang=None, target_lang=None, trainpref='fleurs_data/train', validpref='fleurs_data/valid', testpref=None, align_suffix=None, destdir='fleurs_data/data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict='fleurs_data/dict.du.txt', srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=4, dict_only=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/miniconda3/envs/hubert/bin/fairseq-preprocess\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 389, in cli_main\n",
      "    main(args)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 340, in main\n",
      "    src_dict = _build_dictionary(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 87, in _build_dictionary\n",
      "    return task.build_dictionary(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/tasks/fairseq_task.py\", line 114, in build_dictionary\n",
      "    Dictionary.add_file_to_dictionary(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/dictionary.py\", line 354, in add_file_to_dictionary\n",
      "    offsets = find_offsets(local_file, num_workers)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/file_chunker_utils.py\", line 25, in find_offsets\n",
      "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'fleurs_data/train'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pwd\n",
    "# 4. Chạy lệnh với đường dẫn đúng\n",
    "!fairseq-preprocess \\\n",
    "  --user-dir ../fairseq/examples/speech_to_speech \\\n",
    "  --task speech_to_speech \\\n",
    "  --trainpref fleurs_data/train \\\n",
    "  --validpref fleurs_data/valid \\\n",
    "  --destdir fleurs_data/data-bin \\\n",
    "  --tgtdict fleurs_data/dict.du.txt \\\n",
    "  --workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19302b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanh/Projects/KhoaLuan/src/fleurs_data/unit\n",
      "436\n",
      "371\n"
     ]
    }
   ],
   "source": [
    "# 1. Trích xuất cột Units từ file TSV (Giả sử cột 2 là units)\n",
    "!cut -f2 fleurs_data/train.du.tsv > fleurs_data/train.txt\n",
    "!cut -f2 fleurs_data/validation.tgt.tsv > fleurs_data/valid.txt\n",
    "\n",
    "# Kiểm tra xem file mới tạo có nội dung không\n",
    "!head -n 3 fleurs_data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "033c4dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-16 19:48:57 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2026-01-16 19:48:57 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='../fairseq/examples/speech_to_speech', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='txt', target_lang=None, trainpref='fleurs_data/train', validpref='fleurs_data/valid', testpref=None, align_suffix=None, destdir='fleurs_data/data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='fleurs_data/dict.du.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=4, dict_only=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/miniconda3/envs/hubert/bin/fairseq-preprocess\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 389, in cli_main\n",
      "    main(args)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/preprocess.py\", line 335, in main\n",
      "    src_dict = task.load_dictionary(args.srcdict)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/tasks/fairseq_task.py\", line 94, in load_dictionary\n",
      "    return Dictionary.load(filename)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/dictionary.py\", line 226, in load\n",
      "    d.add_from_file(f)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/dictionary.py\", line 237, in add_from_file\n",
      "    self.add_from_file(fd)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/dictionary.py\", line 261, in add_from_file\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Duplicate word found when loading Dictionary: '<unk>'. Duplicate words can overwrite earlier ones by adding the #fairseq:overwrite flag at the end of the corresponding row in the dictionary file. If using the Camembert model, please download an updated copy of the model file.\n"
     ]
    }
   ],
   "source": [
    "# Xóa thư mục data-bin cũ nếu bị lỗi\n",
    "!rm -rf fleurs_data/data-bin\n",
    "\n",
    "# Chạy lệnh preprocess chuẩn cho Units\n",
    "!fairseq-preprocess \\\n",
    "  --user-dir ../fairseq/examples/speech_to_speech \\\n",
    "  --source-lang txt \\\n",
    "  --trainpref fleurs_data/train \\\n",
    "  --validpref fleurs_data/valid \\\n",
    "  --destdir fleurs_data/data-bin \\\n",
    "  --srcdict fleurs_data/dict.du.txt \\\n",
    "  --workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "808859ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp fleurs_data/dict.du.txt fleurs_data/dict.du.txt.bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b71fe2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa dòng bắt đầu bằng <unk>\n",
    "!sed -i '/^<unk>/d' fleurs_data/dict.du.txt\n",
    "\n",
    "# Xóa dòng bắt đầu bằng <s>\n",
    "!sed -i '/^<s>/d' fleurs_data/dict.du.txt\n",
    "\n",
    "# Xóa dòng bắt đầu bằng </s>\n",
    "!sed -i '/^<\\/s>/d' fleurs_data/dict.du.txt\n",
    "\n",
    "# Xóa dòng bắt đầu bằng <pad>\n",
    "!sed -i '/^<pad>/d' fleurs_data/dict.du.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9ff31b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100000\n",
      "1 100000\n",
      "2 100000\n",
      "3 100000\n",
      "4 100000\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 fleurs_data/dict.du.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70315a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-16 20:41:27 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2026-01-16 20:41:28 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='txt', target_lang=None, trainpref='/home/khanh/Projects/KhoaLuan/src/fleurs_data/train', validpref='/home/khanh/Projects/KhoaLuan/src/fleurs_data/valid', testpref=None, align_suffix=None, destdir='/home/khanh/Projects/KhoaLuan/src/fleurs_data/data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='/home/khanh/Projects/KhoaLuan/src/fleurs_data/dict.du.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=4, dict_only=False)\n",
      "2026-01-16 20:41:28 | INFO | fairseq_cli.preprocess | [txt] Dictionary: 504 types\n",
      "2026-01-16 20:41:28 | INFO | fairseq_cli.preprocess | [txt] /home/khanh/Projects/KhoaLuan/src/fleurs_data/train.txt: 362 sents, 724 tokens, 8.7% replaced (by <unk>)\n",
      "2026-01-16 20:41:28 | INFO | fairseq_cli.preprocess | [txt] Dictionary: 504 types\n",
      "2026-01-16 20:41:28 | INFO | fairseq_cli.preprocess | [txt] /home/khanh/Projects/KhoaLuan/src/fleurs_data/valid.txt: 362 sents, 724 tokens, 50.0% replaced (by <unk>)\n",
      "2026-01-16 20:41:28 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/khanh/Projects/KhoaLuan/src/fleurs_data/data-bin\n",
      "Kiểm tra kết quả:\n",
      "total 36\n",
      "-rw-rw-r-- 1 khanh khanh 5390 Jan 16 20:41 dict.txt.txt\n",
      "-rw-rw-r-- 1 khanh khanh 1805 Jan 16 20:41 preprocess.log\n",
      "-rw-rw-r-- 1 khanh khanh 1448 Jan 16 20:41 train.txt-None.txt.bin\n",
      "-rw-rw-r-- 1 khanh khanh 4370 Jan 16 20:41 train.txt-None.txt.idx\n",
      "-rw-rw-r-- 1 khanh khanh 1448 Jan 16 20:41 valid.txt-None.txt.bin\n",
      "-rw-rw-r-- 1 khanh khanh 4370 Jan 16 20:41 valid.txt-None.txt.idx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Lấy đường dẫn tuyệt đối\n",
    "cwd = os.getcwd()\n",
    "train_pref = os.path.join(cwd, \"fleurs_data/train\")\n",
    "valid_pref = os.path.join(cwd, \"fleurs_data/valid\")\n",
    "dest_dir = os.path.join(cwd, \"fleurs_data/data-bin\")\n",
    "dict_path = os.path.join(cwd, \"fleurs_data/dict.du.txt\")\n",
    "\n",
    "# 2. Kiểm tra file input có tồn tại không trước khi chạy\n",
    "if not os.path.exists(train_pref + \".txt\"):\n",
    "    print(f\"LỖI: Không tìm thấy file {train_pref}.txt\")\n",
    "    print(\"Đang tạo lại file từ train.du.tsv...\")\n",
    "    !cut -f2 fleurs_data/train.du.tsv > fleurs_data/train.txt\n",
    "    !cut -f2 fleurs_data/validation.tgt.tsv > fleurs_data/valid.txt\n",
    "\n",
    "# 3. lệnh Preprocess \n",
    "!rm -rf {dest_dir}  \n",
    "!fairseq-preprocess \\\n",
    "  --source-lang txt \\\n",
    "  --trainpref {train_pref} \\\n",
    "  --validpref {valid_pref} \\\n",
    "  --destdir {dest_dir} \\\n",
    "  --srcdict {dict_path} \\\n",
    "  --only-source \\\n",
    "  --workers 4\n",
    "\n",
    "print(\"Kiểm tra kết quả:\")\n",
    "!ls -l {dest_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "71e4eea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'fleurs_data/train': No such file or directory\n",
      "rm: cannot remove 'fleurs_data/valid': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Xóa symlink hỏng\n",
    "!rm fleurs_data/train fleurs_data/valid\n",
    "\n",
    "# Xóa thư mục data-bin cũ nếu có\n",
    "!rm -rf fleurs_data/data-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf381529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
