{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485d6f37",
   "metadata": {},
   "source": [
    "bước đầu tiên sử lý hết dữ liệu đầu vào "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7507f909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 2602 (source in train) file audio. Bắt đầu xử lý...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2602/2602 [00:23<00:00, 108.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã hoàn tất chuẩn hóa dữ liệu về 16kHz!\n",
      "Dữ liệu mới nằm tại: /home/khanh/Projects/KhoaLuan/my_data/source_wav_16k/train/\n",
      "Tìm thấy 647 (source in test) file audio. Bắt đầu xử lý...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [00:05<00:00, 128.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã hoàn tất chuẩn hóa dữ liệu về 16kHz!\n",
      "Dữ liệu mới nằm tại: /home/khanh/Projects/KhoaLuan/my_data/source_wav_16k/test/\n",
      "Tìm thấy 394 (source in valid) file audio. Bắt đầu xử lý...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [00:03<00:00, 112.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã hoàn tất chuẩn hóa dữ liệu về 16kHz!\n",
      "Dữ liệu mới nằm tại: /home/khanh/Projects/KhoaLuan/my_data/source_wav_16k/valid/\n",
      "Tìm thấy 2994 (target in train) file audio. Bắt đầu xử lý...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2994/2994 [00:34<00:00, 86.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã hoàn tất chuẩn hóa dữ liệu về 16kHz!\n",
      "Dữ liệu mới nằm tại: /home/khanh/Projects/KhoaLuan/my_data/target_wav_16k/train/\n",
      "Tìm thấy 857 (target in test) file audio. Bắt đầu xử lý...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 857/857 [00:14<00:00, 60.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã hoàn tất chuẩn hóa dữ liệu về 16kHz!\n",
      "Dữ liệu mới nằm tại: /home/khanh/Projects/KhoaLuan/my_data/target_wav_16k/test/\n",
      "Tìm thấy 361 (target in valid) file audio. Bắt đầu xử lý...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:06<00:00, 58.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã hoàn tất chuẩn hóa dữ liệu về 16kHz!\n",
      "Dữ liệu mới nằm tại: /home/khanh/Projects/KhoaLuan/my_data/target_wav_16k/valid/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#  chuẩn hóa giá trị đầu vào cho dataset \n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CẤU HÌNH ---\n",
    "# Thư mục chứa file wav gốc (Tiếng Việt)\n",
    "folder = ['source' , 'target']\n",
    "file = ['train' , 'test',  'valid']\n",
    "\n",
    "TARGET_SAMPLE_RATE = 16000\n",
    "# ----------------\n",
    "\n",
    "def convert_to_16k(input_path, output_path):\n",
    "    try:\n",
    "        # Load audio\n",
    "        waveform, sample_rate = torchaudio.load(input_path)\n",
    "\n",
    "        # 1. Chuyển về Mono (nếu đang là Stereo)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "        # 2. Resample về 16000Hz (nếu chưa đúng)\n",
    "        if sample_rate != TARGET_SAMPLE_RATE:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=TARGET_SAMPLE_RATE)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Tạo thư mục cha nếu chưa có\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # Lưu file\n",
    "        torchaudio.save(output_path, waveform, TARGET_SAMPLE_RATE)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi file {input_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Tìm tất cả file wav trong thư mục input (bao gồm cả thư mục con)\n",
    "    for i in folder:\n",
    "        for   j in file:\n",
    "            INPUT_DIR = f\"/home/khanh/Projects/KhoaLuan/my_data/{i}_audio/{j}/\" \n",
    "\n",
    "            # Thư mục lưu j đã chuẩn hóa (Sẽ tự tạo nếu chưa có)\n",
    "            OUTPUT_DIR = f\"/home/khanh/Projects/KhoaLuan/my_data/{i}_wav_16k/{j}/\"\n",
    "\n",
    "            files = glob.glob(os.path.join(INPUT_DIR, \"**/*.wav\"), recursive=True)\n",
    "        \n",
    "            print(f\"Tìm thấy {len(files)} ({i} in {j}) file audio. Bắt đầu xử lý...\")\n",
    "\n",
    "            for file_path in tqdm(files):\n",
    "                # Tạo đường dẫn output tương ứng\n",
    "                relative_path = os.path.relpath(file_path, INPUT_DIR)\n",
    "                output_path = os.path.join(OUTPUT_DIR, relative_path)\n",
    "                \n",
    "                convert_to_16k(file_path, output_path)\n",
    "\n",
    "            print(\"✅ Đã hoàn tất chuẩn hóa dữ liệu về 16kHz!\")\n",
    "            print(f\"Dữ liệu mới nằm tại: {OUTPUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52726c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ cấu trúc thư mục của bạn: /data/en-vi/train/wav_en/ và /data/en-vi/train/wav_vi/\n",
    "\n",
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py my_data/source_wav_16k/train --dest manifest_temp/train_en --ext wav --valid-percent 0\n",
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py my_data/target_wav_16k/train --dest manifest_temp/train_vn --ext wav --valid-percent 0\n",
    "# valid  \n",
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py my_data/target_wav_16k/valid --dest manifest_temp/dev_vn --ext wav --valid-percent 0\n",
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py my_data/source_wav_16k/valid  --dest manifest_temp/dev_en --ext wav --valid-percent 0\n",
    "\n",
    "#  test \n",
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py my_data/source_wav_16k/test --dest manifest_temp/test_en --ext wav --valid-percent 0\n",
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py my_data/target_wav_16k/test --dest manifest_temp/test_vn --ext wav --valid-percent 0\n",
    "\n",
    "\n",
    "\n",
    "# !cp manifest_temp/dev_en/train.tsv manifest_temp/source/valid.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a50cace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p  manifest_temp/source\n",
    "# source\n",
    "!cp manifest_temp/dev_en/train.tsv manifest_temp/source/valid.tsv\n",
    "\n",
    "!cp manifest_temp/train_en/train.tsv manifest_temp/source/train.tsv\n",
    "!cp manifest_temp/test_en/train.tsv manifest_temp/source/test.tsv\n",
    "# target\n",
    "!mkdir -p manifest_temp/target\n",
    "!cp manifest_temp/dev_vn/train.tsv manifest_temp/target/valid.tsv\n",
    "!cp manifest_temp/train_vn/train.tsv manifest_temp/target/train.tsv\n",
    "!cp manifest_temp/test_vn//train.tsv manifest_temp/target/test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d57cfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xoa thu muc cu di \n",
    "!rm -r manifest_temp/dev_vn/\n",
    "!rm -r manifest_temp/dev_en/\n",
    "!rm -r manifest_temp/train_en/\n",
    "!rm -r manifest_temp/train_vn/\n",
    "!rm -r manifest_temp/test_en/\n",
    "!rm -r manifest_temp/test_vn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "074aaf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-22 10:36:25 | INFO | dump_hubert_feature | Namespace(tsv_dir='/home/khanh/Projects/KhoaLuan/manifest_temp/target', split='train', ckpt_path='/home/khanh/Projects/KhoaLuan/checkpoints/mhubert_base_vp_en_es_fr_it3.pt', layer=9, nshard=1, rank=0, feat_dir='/home/khanh/Projects/KhoaLuan/hubert_feats', max_chunk=1600000)\n",
      "2026-01-22 10:36:26 | INFO | fairseq.tasks.hubert_pretraining | current directory is /home/khanh/Projects/KhoaLuan\n",
      "2026-01-22 10:36:26 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/home/khanh/Projects/KhoaLuan/checkpoints/', 'fine_tuning': False, 'labels': ['km'], 'label_dir': '/checkpoint/wnhsu/experiments/hubert/kmeans/mhubert_vp_en_es_fr_it2_400k/en_es_fr.layer9.km500', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2026-01-22 10:36:26 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'conv_pos_batch_norm': False, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n",
      "/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "2026-01-22 10:36:27 | INFO | dump_hubert_feature | TASK CONFIG:\n",
      "{'_name': 'hubert_pretraining', 'data': '/home/khanh/Projects/KhoaLuan/checkpoints/', 'fine_tuning': False, 'labels': ['km'], 'label_dir': '/checkpoint/wnhsu/experiments/hubert/kmeans/mhubert_vp_en_es_fr_it2_400k/en_es_fr.layer9.km500', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2026-01-22 10:36:27 | INFO | dump_hubert_feature |  max_chunk = 1600000\n",
      "2026-01-22 10:36:27 | INFO | feature_utils | rank 0 of 1, process 2994 (0-2994) out of 2994\n",
      "100%|███████████████████████████████████████| 2994/2994 [06:03<00:00,  8.24it/s]\n",
      "2026-01-22 10:42:31 | INFO | feature_utils | finished successfully\n"
     ]
    }
   ],
   "source": [
    "# Tạo thư mục chứa feature tạm thời\n",
    "!mkdir -p /home/khanh/Projects/KhoaLuan/hubert_feats\n",
    "\n",
    "# Chạy lệnh dump (Lưu ý thay HUBERT_PATH đúng chỗ bạn vừa tải)\n",
    "!python fairseq/examples/hubert/simple_kmeans/dump_hubert_feature.py \\\n",
    "    /home/khanh/Projects/KhoaLuan/manifest_temp/target \\\n",
    "    train \\\n",
    "    /home/khanh/Projects/KhoaLuan/checkpoints/mhubert_base_vp_en_es_fr_it3.pt \\\n",
    "    9 \\\n",
    "    1 \\\n",
    "    0 \\\n",
    "    /home/khanh/Projects/KhoaLuan/hubert_feats \\\n",
    "    --max_chunk 1600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "525d395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-22 00:21:40 | INFO | root | Namespace(feat_dir='/home/khanh/Projects/KhoaLuan/hubert_feats', split='train', nshard=1, km_path='/home/khanh/Projects/KhoaLuan/kmeans_model.joblib', n_clusters=100, seed=0, percent=0.1, init='k-means++', max_iter=100, batch_size=10000, tol=0.0, max_no_improvement=100, n_init=20, reassignment_ratio=0.0)\n",
      "2026-01-22 00:21:41 | INFO | learn_kmeans | sampled 300 utterances, 157914 frames from shard 0/1\n",
      "2026-01-22 00:21:42 | INFO | root | loaded feature with dimension (157914, 768)\n",
      "Init 1/20 with method k-means++\n",
      "Inertia for init 1/20: 2102450.5\n",
      "Init 2/20 with method k-means++\n",
      "Inertia for init 2/20: 2103638.75\n",
      "Init 3/20 with method k-means++\n",
      "Inertia for init 3/20: 2091183.75\n",
      "Init 4/20 with method k-means++\n",
      "Inertia for init 4/20: 2110545.5\n",
      "Init 5/20 with method k-means++\n",
      "Inertia for init 5/20: 2100426.25\n",
      "Init 6/20 with method k-means++\n",
      "Inertia for init 6/20: 2091635.25\n",
      "Init 7/20 with method k-means++\n",
      "Inertia for init 7/20: 2089754.25\n",
      "Init 8/20 with method k-means++\n",
      "Inertia for init 8/20: 2102493.75\n",
      "Init 9/20 with method k-means++\n",
      "Inertia for init 9/20: 2103920.0\n",
      "Init 10/20 with method k-means++\n",
      "Inertia for init 10/20: 2079904.75\n",
      "Init 11/20 with method k-means++\n",
      "Inertia for init 11/20: 2103350.75\n",
      "Init 12/20 with method k-means++\n",
      "Inertia for init 12/20: 2097189.5\n",
      "Init 13/20 with method k-means++\n",
      "Inertia for init 13/20: 2087983.25\n",
      "Init 14/20 with method k-means++\n",
      "Inertia for init 14/20: 2086272.5\n",
      "Init 15/20 with method k-means++\n",
      "Inertia for init 15/20: 2102119.5\n",
      "Init 16/20 with method k-means++\n",
      "Inertia for init 16/20: 2095567.75\n",
      "Init 17/20 with method k-means++\n",
      "Inertia for init 17/20: 2097618.25\n",
      "Init 18/20 with method k-means++\n",
      "Inertia for init 18/20: 2077285.5\n",
      "Init 19/20 with method k-means++\n",
      "Inertia for init 19/20: 2101958.75\n",
      "Init 20/20 with method k-means++\n",
      "Inertia for init 20/20: 2097630.25\n",
      "Minibatch step 1/1579: mean batch inertia: 69.617425\n",
      "Minibatch step 2/1579: mean batch inertia: 43.8046, ewa inertia: 43.8046\n",
      "Minibatch step 3/1579: mean batch inertia: 43.295246875, ewa inertia: 43.74009021625558\n",
      "Minibatch step 4/1579: mean batch inertia: 42.95144375, ewa inertia: 43.64020781543798\n",
      "Minibatch step 5/1579: mean batch inertia: 42.84018125, ewa inertia: 43.538884120356705\n",
      "Minibatch step 6/1579: mean batch inertia: 42.720575, ewa inertia: 43.435244932140684\n",
      "Minibatch step 7/1579: mean batch inertia: 42.459653125, ewa inertia: 43.31168582665474\n",
      "Minibatch step 8/1579: mean batch inertia: 42.544284375, ewa inertia: 43.21449411571471\n",
      "Minibatch step 9/1579: mean batch inertia: 42.4111625, ewa inertia: 43.11275183465025\n",
      "Minibatch step 10/1579: mean batch inertia: 42.544665625, ewa inertia: 43.04080348146655\n",
      "Minibatch step 11/1579: mean batch inertia: 42.3944375, ewa inertia: 42.958940962837346\n",
      "Minibatch step 12/1579: mean batch inertia: 42.304059375, ewa inertia: 42.87599993914266\n",
      "Minibatch step 13/1579: mean batch inertia: 42.485109375, ewa inertia: 42.826493487679194\n",
      "Minibatch step 14/1579: mean batch inertia: 42.37743125, ewa inertia: 42.76961956972597\n",
      "Minibatch step 15/1579: mean batch inertia: 42.4612375, ewa inertia: 42.73056285317264\n",
      "Minibatch step 16/1579: mean batch inertia: 42.180546875, ewa inertia: 42.660903102272144\n",
      "Minibatch step 17/1579: mean batch inertia: 42.4197875, ewa inertia: 42.63036571161614\n",
      "Minibatch step 18/1579: mean batch inertia: 42.2493875, ewa inertia: 42.58211466369592\n",
      "Minibatch step 19/1579: mean batch inertia: 42.238521875, ewa inertia: 42.538598495036084\n",
      "Minibatch step 20/1579: mean batch inertia: 42.2011625, ewa inertia: 42.495862086837235\n",
      "Minibatch step 21/1579: mean batch inertia: 42.181265625, ewa inertia: 42.456018314955244\n",
      "Minibatch step 22/1579: mean batch inertia: 42.015075, ewa inertia: 42.400172661919726\n",
      "Minibatch step 23/1579: mean batch inertia: 42.190375, ewa inertia: 42.373601701349834\n",
      "Minibatch step 24/1579: mean batch inertia: 42.23545625, ewa inertia: 42.356105522855096\n",
      "Minibatch step 25/1579: mean batch inertia: 42.32764375, ewa inertia: 42.35250082756268\n",
      "Minibatch step 26/1579: mean batch inertia: 42.27504375, ewa inertia: 42.342690856684335\n",
      "Minibatch step 27/1579: mean batch inertia: 42.200225, ewa inertia: 42.3246474970688\n",
      "Minibatch step 28/1579: mean batch inertia: 42.13885625, ewa inertia: 42.30111695885916\n",
      "Minibatch step 29/1579: mean batch inertia: 42.18755625, ewa inertia: 42.28673444815921\n",
      "Minibatch step 30/1579: mean batch inertia: 42.157453125, ewa inertia: 42.27036091516245\n",
      "Minibatch step 31/1579: mean batch inertia: 42.11186875, ewa inertia: 42.250287816956146\n",
      "Minibatch step 32/1579: mean batch inertia: 42.129984375, ewa inertia: 42.23505133632339\n",
      "Minibatch step 33/1579: mean batch inertia: 42.247375, ewa inertia: 42.23661213342013\n",
      "Minibatch step 34/1579: mean batch inertia: 42.24603125, ewa inertia: 42.23780506842692\n",
      "Minibatch step 35/1579: mean batch inertia: 42.136253125, ewa inertia: 42.22494347283095\n",
      "Minibatch step 36/1579: mean batch inertia: 42.1562125, ewa inertia: 42.21623866672248\n",
      "Minibatch step 37/1579: mean batch inertia: 41.94935625, ewa inertia: 42.18243789836958\n",
      "Minibatch step 38/1579: mean batch inertia: 42.230590625, ewa inertia: 42.18853646109389\n",
      "Minibatch step 39/1579: mean batch inertia: 42.2271, ewa inertia: 42.19342054923069\n",
      "Minibatch step 40/1579: mean batch inertia: 42.06406875, ewa inertia: 42.177038090410356\n",
      "Minibatch step 41/1579: mean batch inertia: 42.08054375, ewa inertia: 42.16481704232622\n",
      "Minibatch step 42/1579: mean batch inertia: 41.96255625, ewa inertia: 42.139200629404556\n",
      "Minibatch step 43/1579: mean batch inertia: 41.990915625, ewa inertia: 42.1204202723258\n",
      "Minibatch step 44/1579: mean batch inertia: 42.314215625, ewa inertia: 42.14496453381764\n",
      "Minibatch step 45/1579: mean batch inertia: 42.0372625, ewa inertia: 42.131324026732486\n",
      "Minibatch step 46/1579: mean batch inertia: 42.223459375, ewa inertia: 42.14299300666062\n",
      "Minibatch step 47/1579: mean batch inertia: 42.03204375, ewa inertia: 42.12894123746065\n",
      "Minibatch step 48/1579: mean batch inertia: 42.25295, ewa inertia: 42.144646998476304\n",
      "Minibatch step 49/1579: mean batch inertia: 42.21830625, ewa inertia: 42.15397597311756\n",
      "Minibatch step 50/1579: mean batch inertia: 41.9992625, ewa inertia: 42.13438144782009\n",
      "Minibatch step 51/1579: mean batch inertia: 41.9041875, ewa inertia: 42.10522728921324\n",
      "Minibatch step 52/1579: mean batch inertia: 42.235125, ewa inertia: 42.12167888795773\n",
      "Minibatch step 53/1579: mean batch inertia: 42.104678125, ewa inertia: 42.11952573430447\n",
      "Minibatch step 54/1579: mean batch inertia: 42.04415, ewa inertia: 42.10997936640978\n",
      "Minibatch step 55/1579: mean batch inertia: 42.06155625, ewa inertia: 42.1038465587082\n",
      "Minibatch step 56/1579: mean batch inertia: 42.24469375, ewa inertia: 42.12168491368294\n",
      "Minibatch step 57/1579: mean batch inertia: 42.098896875, ewa inertia: 42.1187987991678\n",
      "Minibatch step 58/1579: mean batch inertia: 42.230825, ewa inertia: 42.132986963792085\n",
      "Minibatch step 59/1579: mean batch inertia: 42.009225, ewa inertia: 42.11731245993975\n",
      "Minibatch step 60/1579: mean batch inertia: 42.1810875, ewa inertia: 42.12538959511504\n",
      "Minibatch step 61/1579: mean batch inertia: 41.8727125, ewa inertia: 42.09338793661331\n",
      "Minibatch step 62/1579: mean batch inertia: 42.15318125, ewa inertia: 42.10096078446015\n",
      "Minibatch step 63/1579: mean batch inertia: 41.880171875, ewa inertia: 42.07299777784772\n",
      "Minibatch step 64/1579: mean batch inertia: 42.011309375, ewa inertia: 42.065184916137596\n",
      "Minibatch step 65/1579: mean batch inertia: 41.967190625, ewa inertia: 42.052773898674076\n",
      "Minibatch step 66/1579: mean batch inertia: 42.2691125, ewa inertia: 42.08017327192246\n",
      "Minibatch step 67/1579: mean batch inertia: 41.881246875, ewa inertia: 42.054979161556446\n",
      "Minibatch step 68/1579: mean batch inertia: 42.047015625, ewa inertia: 42.05397057636107\n",
      "Minibatch step 69/1579: mean batch inertia: 42.10543125, ewa inertia: 42.06048809194083\n",
      "Minibatch step 70/1579: mean batch inertia: 42.08505625, ewa inertia: 42.06359965931052\n",
      "Minibatch step 71/1579: mean batch inertia: 42.036571875, ewa inertia: 42.060176579259796\n",
      "Minibatch step 72/1579: mean batch inertia: 42.297190625, ewa inertia: 42.09019450608628\n",
      "Minibatch step 73/1579: mean batch inertia: 42.0754875, ewa inertia: 42.08833185768856\n",
      "Minibatch step 74/1579: mean batch inertia: 42.102046875, ewa inertia: 42.090068870298055\n",
      "Minibatch step 75/1579: mean batch inertia: 41.940025, ewa inertia: 42.07106575212713\n",
      "Minibatch step 76/1579: mean batch inertia: 41.95855625, ewa inertia: 42.056816377194146\n",
      "Minibatch step 77/1579: mean batch inertia: 42.0725, ewa inertia: 42.05880271450294\n",
      "Minibatch step 78/1579: mean batch inertia: 42.058553125, ewa inertia: 42.05877110388926\n",
      "Minibatch step 79/1579: mean batch inertia: 42.11805625, ewa inertia: 42.06627959214063\n",
      "Minibatch step 80/1579: mean batch inertia: 42.1863625, ewa inertia: 42.08148814203892\n",
      "Minibatch step 81/1579: mean batch inertia: 41.679325, ewa inertia: 42.0305540139271\n",
      "Minibatch step 82/1579: mean batch inertia: 41.961925, ewa inertia: 42.02186212095594\n",
      "Minibatch step 83/1579: mean batch inertia: 42.222759375, ewa inertia: 42.047305841190756\n",
      "Minibatch step 84/1579: mean batch inertia: 42.264, ewa inertia: 42.074750245941324\n",
      "Minibatch step 85/1579: mean batch inertia: 42.221615625, ewa inertia: 42.093350806883436\n",
      "Minibatch step 86/1579: mean batch inertia: 42.0875, ewa inertia: 42.09260979977411\n",
      "Minibatch step 87/1579: mean batch inertia: 42.021646875, ewa inertia: 42.0836223160298\n",
      "Minibatch step 88/1579: mean batch inertia: 41.997415625, ewa inertia: 42.072704202990536\n",
      "Minibatch step 89/1579: mean batch inertia: 42.164140625, ewa inertia: 42.08428466361929\n",
      "Minibatch step 90/1579: mean batch inertia: 42.166365625, ewa inertia: 42.09468025129377\n",
      "Minibatch step 91/1579: mean batch inertia: 42.19326875, ewa inertia: 42.107166525391385\n",
      "Minibatch step 92/1579: mean batch inertia: 41.87349375, ewa inertia: 42.07757177183518\n",
      "Minibatch step 93/1579: mean batch inertia: 41.91070625, ewa inertia: 42.05643818454643\n",
      "Minibatch step 94/1579: mean batch inertia: 42.045946875, ewa inertia: 42.0551094558574\n",
      "Minibatch step 95/1579: mean batch inertia: 42.0182375, ewa inertia: 42.05043960741268\n",
      "Minibatch step 96/1579: mean batch inertia: 42.2150375, ewa inertia: 42.07128599852021\n",
      "Minibatch step 97/1579: mean batch inertia: 41.942303125, ewa inertia: 42.054950264293545\n",
      "Minibatch step 98/1579: mean batch inertia: 41.965190625, ewa inertia: 42.043582168888605\n",
      "Minibatch step 99/1579: mean batch inertia: 42.180046875, ewa inertia: 42.06086548030442\n",
      "Minibatch step 100/1579: mean batch inertia: 42.232940625, ewa inertia: 42.08265886848105\n",
      "Minibatch step 101/1579: mean batch inertia: 41.70578125, ewa inertia: 42.03492716237574\n",
      "Minibatch step 102/1579: mean batch inertia: 42.265803125, ewa inertia: 42.06416769843935\n",
      "Minibatch step 103/1579: mean batch inertia: 42.17288125, ewa inertia: 42.07793631466462\n",
      "Minibatch step 104/1579: mean batch inertia: 42.05879375, ewa inertia: 42.0755119009402\n",
      "Minibatch step 105/1579: mean batch inertia: 42.12260625, ewa inertia: 42.08147641970787\n",
      "Minibatch step 106/1579: mean batch inertia: 42.1149125, ewa inertia: 42.08571111309256\n",
      "Minibatch step 107/1579: mean batch inertia: 41.95683125, ewa inertia: 42.06938842517912\n",
      "Minibatch step 108/1579: mean batch inertia: 41.900471875, ewa inertia: 42.04799507430313\n",
      "Minibatch step 109/1579: mean batch inertia: 42.2404125, ewa inertia: 42.07236482077394\n",
      "Minibatch step 110/1579: mean batch inertia: 41.912175, ewa inertia: 42.05207671378298\n",
      "Minibatch step 111/1579: mean batch inertia: 42.244834375, ewa inertia: 42.076489551223\n",
      "Minibatch step 112/1579: mean batch inertia: 42.11215625, ewa inertia: 42.08100675336048\n",
      "Minibatch step 113/1579: mean batch inertia: 42.15988125, ewa inertia: 42.09099624095058\n",
      "Minibatch step 114/1579: mean batch inertia: 41.928525, ewa inertia: 42.070419191151565\n",
      "Minibatch step 115/1579: mean batch inertia: 41.9218125, ewa inertia: 42.051598092313384\n",
      "Minibatch step 116/1579: mean batch inertia: 41.9931, ewa inertia: 42.044189284750665\n",
      "Minibatch step 117/1579: mean batch inertia: 42.0522125, ewa inertia: 42.045205428277164\n",
      "Minibatch step 118/1579: mean batch inertia: 42.075625, ewa inertia: 42.04905807960514\n",
      "Minibatch step 119/1579: mean batch inertia: 42.0812875, ewa inertia: 42.053139949015254\n",
      "Minibatch step 120/1579: mean batch inertia: 42.20176875, ewa inertia: 42.07196384807295\n",
      "Minibatch step 121/1579: mean batch inertia: 41.984015625, ewa inertia: 42.060825169280825\n",
      "Minibatch step 122/1579: mean batch inertia: 41.920084375, ewa inertia: 42.04300028953149\n",
      "Minibatch step 123/1579: mean batch inertia: 42.024371875, ewa inertia: 42.04064099313388\n",
      "Minibatch step 124/1579: mean batch inertia: 42.249296875, ewa inertia: 42.0670673467882\n",
      "Minibatch step 125/1579: mean batch inertia: 42.10994375, ewa inertia: 42.07249766097138\n",
      "Minibatch step 126/1579: mean batch inertia: 41.901334375, ewa inertia: 42.05081976007895\n",
      "Minibatch step 127/1579: mean batch inertia: 42.196428125, ewa inertia: 42.069261119661135\n",
      "Minibatch step 128/1579: mean batch inertia: 41.861371875, ewa inertia: 42.0429318609256\n",
      "Minibatch step 129/1579: mean batch inertia: 42.233403125, ewa inertia: 42.06705512522277\n",
      "Minibatch step 130/1579: mean batch inertia: 41.9546125, ewa inertia: 42.052814220277355\n",
      "Minibatch step 131/1579: mean batch inertia: 42.132, ewa inertia: 42.062843131998555\n",
      "Minibatch step 132/1579: mean batch inertia: 42.330875, ewa inertia: 42.0967894788309\n",
      "Minibatch step 133/1579: mean batch inertia: 42.1913625, ewa inertia: 42.108767191039256\n",
      "Minibatch step 134/1579: mean batch inertia: 42.0902625, ewa inertia: 42.10642356427306\n",
      "Minibatch step 135/1579: mean batch inertia: 41.90213125, ewa inertia: 42.08054985825741\n",
      "Minibatch step 136/1579: mean batch inertia: 41.936975, ewa inertia: 42.06236604313442\n",
      "Minibatch step 137/1579: mean batch inertia: 42.07266875, ewa inertia: 42.06367088521599\n",
      "Minibatch step 138/1579: mean batch inertia: 41.970890625, ewa inertia: 42.051920226923116\n",
      "Minibatch step 139/1579: mean batch inertia: 42.072896875, ewa inertia: 42.054576928069544\n",
      "Minibatch step 140/1579: mean batch inertia: 42.07090625, ewa inertia: 42.05664504343926\n",
      "Minibatch step 141/1579: mean batch inertia: 42.02818125, ewa inertia: 42.05304009223903\n",
      "Minibatch step 142/1579: mean batch inertia: 42.056640625, ewa inertia: 42.053496101200935\n",
      "Minibatch step 143/1579: mean batch inertia: 42.116825, ewa inertia: 42.061516732401145\n",
      "Minibatch step 144/1579: mean batch inertia: 42.2794375, ewa inertia: 42.08911648766175\n",
      "Minibatch step 145/1579: mean batch inertia: 41.95866875, ewa inertia: 42.07259522778628\n",
      "Minibatch step 146/1579: mean batch inertia: 42.05523125, ewa inertia: 42.070396072824906\n",
      "Minibatch step 147/1579: mean batch inertia: 42.17328125, ewa inertia: 42.08342652302598\n",
      "Minibatch step 148/1579: mean batch inertia: 41.92354375, ewa inertia: 42.06317730375916\n",
      "Minibatch step 149/1579: mean batch inertia: 41.97964375, ewa inertia: 42.05259774465976\n",
      "Minibatch step 150/1579: mean batch inertia: 41.89099375, ewa inertia: 42.03213053196182\n",
      "Minibatch step 151/1579: mean batch inertia: 41.90680625, ewa inertia: 42.016258159867746\n",
      "Minibatch step 152/1579: mean batch inertia: 42.074790625, ewa inertia: 42.02367132076218\n",
      "Minibatch step 153/1579: mean batch inertia: 41.915240625, ewa inertia: 42.00993852834067\n",
      "Minibatch step 154/1579: mean batch inertia: 42.28865625, ewa inertia: 42.04523824295415\n",
      "Minibatch step 155/1579: mean batch inertia: 42.18671875, ewa inertia: 42.063156807630826\n",
      "Minibatch step 156/1579: mean batch inertia: 41.6952125, ewa inertia: 42.01655650903591\n",
      "Minibatch step 157/1579: mean batch inertia: 41.897625, ewa inertia: 42.00149378427437\n",
      "Minibatch step 158/1579: mean batch inertia: 42.018221875, ewa inertia: 42.00361240387677\n",
      "Minibatch step 159/1579: mean batch inertia: 41.961875, ewa inertia: 41.99832634443001\n",
      "Minibatch step 160/1579: mean batch inertia: 42.103834375, ewa inertia: 42.011688980097304\n",
      "Minibatch step 161/1579: mean batch inertia: 42.11083125, ewa inertia: 42.02424538954577\n",
      "Minibatch step 162/1579: mean batch inertia: 42.07398125, ewa inertia: 42.03054445682301\n",
      "Minibatch step 163/1579: mean batch inertia: 41.948309375, ewa inertia: 42.020129349730844\n",
      "Minibatch step 164/1579: mean batch inertia: 41.9440125, ewa inertia: 42.01048911926119\n",
      "Minibatch step 165/1579: mean batch inertia: 41.908921875, ewa inertia: 41.99762558580823\n",
      "Minibatch step 166/1579: mean batch inertia: 42.11784375, ewa inertia: 42.0128512659769\n",
      "Minibatch step 167/1579: mean batch inertia: 41.79041875, ewa inertia: 41.984680095919984\n",
      "Minibatch step 168/1579: mean batch inertia: 42.10526875, ewa inertia: 41.99995269878609\n",
      "Minibatch step 169/1579: mean batch inertia: 41.7555375, ewa inertia: 41.96899741286821\n",
      "Minibatch step 170/1579: mean batch inertia: 42.0864625, ewa inertia: 41.98387441468967\n",
      "Minibatch step 171/1579: mean batch inertia: 42.063403125, ewa inertia: 41.9939467587115\n",
      "Minibatch step 172/1579: mean batch inertia: 41.979603125, ewa inertia: 41.9921301315752\n",
      "Minibatch step 173/1579: mean batch inertia: 42.061459375, ewa inertia: 42.000910708901586\n",
      "Minibatch step 174/1579: mean batch inertia: 42.05995625, ewa inertia: 42.00838885107914\n",
      "Minibatch step 175/1579: mean batch inertia: 41.8618, ewa inertia: 41.9898233125199\n",
      "Minibatch step 176/1579: mean batch inertia: 42.01474375, ewa inertia: 41.99297949622381\n",
      "Minibatch step 177/1579: mean batch inertia: 41.785971875, ewa inertia: 41.96676189546089\n",
      "Minibatch step 178/1579: mean batch inertia: 42.03303125, ewa inertia: 41.97515493659557\n",
      "Minibatch step 179/1579: mean batch inertia: 41.9466875, ewa inertia: 41.97154952398809\n",
      "Minibatch step 180/1579: mean batch inertia: 42.0041875, ewa inertia: 41.97568313713591\n",
      "Minibatch step 181/1579: mean batch inertia: 42.12416875, ewa inertia: 41.99448890135895\n",
      "Minibatch step 182/1579: mean batch inertia: 42.28291875, ewa inertia: 42.03101866086768\n",
      "Minibatch step 183/1579: mean batch inertia: 42.1716375, ewa inertia: 42.04882809494707\n",
      "Minibatch step 184/1579: mean batch inertia: 41.74299375, ewa inertia: 42.010094048789696\n",
      "Minibatch step 185/1579: mean batch inertia: 41.8306, ewa inertia: 41.98736105334408\n",
      "Minibatch step 186/1579: mean batch inertia: 42.04988125, ewa inertia: 41.995279262083706\n",
      "Minibatch step 187/1579: mean batch inertia: 42.115484375, ewa inertia: 42.010503289302946\n",
      "Minibatch step 188/1579: mean batch inertia: 42.0483875, ewa inertia: 42.01530134024137\n",
      "Minibatch step 189/1579: mean batch inertia: 41.967925, ewa inertia: 42.009301107174046\n",
      "Minibatch step 190/1579: mean batch inertia: 41.986675, ewa inertia: 42.00643550135141\n",
      "Minibatch step 191/1579: mean batch inertia: 42.06860625, ewa inertia: 42.01430945235653\n",
      "Minibatch step 192/1579: mean batch inertia: 42.13659375, ewa inertia: 42.02979680918058\n",
      "Minibatch step 193/1579: mean batch inertia: 41.9869125, ewa inertia: 42.02436549370319\n",
      "Minibatch step 194/1579: mean batch inertia: 42.028140625, ewa inertia: 42.024843615641814\n",
      "Minibatch step 195/1579: mean batch inertia: 42.0262125, ewa inertia: 42.0250169854114\n",
      "Minibatch step 196/1579: mean batch inertia: 41.97709375, ewa inertia: 42.01894748784481\n",
      "Minibatch step 197/1579: mean batch inertia: 42.00029375, ewa inertia: 42.0165849842391\n",
      "Minibatch step 198/1579: mean batch inertia: 42.0139125, ewa inertia: 42.01624651300596\n",
      "Minibatch step 199/1579: mean batch inertia: 41.94574375, ewa inertia: 42.00731730893973\n",
      "Minibatch step 200/1579: mean batch inertia: 42.056221875, ewa inertia: 42.013511092438485\n",
      "Minibatch step 201/1579: mean batch inertia: 41.95315, ewa inertia: 42.005866335140134\n",
      "Minibatch step 202/1579: mean batch inertia: 41.908725, ewa inertia: 41.99356334490613\n",
      "Minibatch step 203/1579: mean batch inertia: 41.872484375, ewa inertia: 41.978228643338056\n",
      "Minibatch step 204/1579: mean batch inertia: 42.06581875, ewa inertia: 41.98932196653876\n",
      "Minibatch step 205/1579: mean batch inertia: 41.89375625, ewa inertia: 41.97721852905167\n",
      "Minibatch step 206/1579: mean batch inertia: 42.039675, ewa inertia: 41.9851286669041\n",
      "Minibatch step 207/1579: mean batch inertia: 41.859421875, ewa inertia: 41.969207849767784\n",
      "Minibatch step 208/1579: mean batch inertia: 41.78785, ewa inertia: 41.94623880315818\n",
      "Minibatch step 209/1579: mean batch inertia: 42.2379, ewa inertia: 41.98317781425172\n",
      "Minibatch step 210/1579: mean batch inertia: 42.007384375, ewa inertia: 41.98624358517257\n",
      "Minibatch step 211/1579: mean batch inertia: 42.139909375, ewa inertia: 42.00570542094846\n",
      "Minibatch step 212/1579: mean batch inertia: 42.071971875, ewa inertia: 42.01409809473518\n",
      "Minibatch step 213/1579: mean batch inertia: 42.08310625, ewa inertia: 42.02283800611344\n",
      "Minibatch step 214/1579: mean batch inertia: 42.110734375, ewa inertia: 42.03397011755143\n",
      "Minibatch step 215/1579: mean batch inertia: 41.989415625, ewa inertia: 42.028327272660015\n",
      "Minibatch step 216/1579: mean batch inertia: 42.12188125, ewa inertia: 42.04017592254635\n",
      "Minibatch step 217/1579: mean batch inertia: 41.856325, ewa inertia: 42.016891127239205\n",
      "Minibatch step 218/1579: mean batch inertia: 41.81633125, ewa inertia: 41.99149013591612\n",
      "Minibatch step 219/1579: mean batch inertia: 41.984325, ewa inertia: 41.99058266849173\n",
      "Minibatch step 220/1579: mean batch inertia: 42.06636875, ewa inertia: 42.00018100702934\n",
      "Minibatch step 221/1579: mean batch inertia: 42.1487875, ewa inertia: 42.019002080767834\n",
      "Minibatch step 222/1579: mean batch inertia: 41.893853125, ewa inertia: 42.003151913808665\n",
      "Minibatch step 223/1579: mean batch inertia: 41.70820625, ewa inertia: 41.965796923616644\n",
      "Minibatch step 224/1579: mean batch inertia: 42.1995625, ewa inertia: 41.995403430456825\n",
      "Minibatch step 225/1579: mean batch inertia: 42.381534375, ewa inertia: 42.04430707413136\n",
      "Minibatch step 226/1579: mean batch inertia: 42.05819375, ewa inertia: 42.046065827368054\n",
      "Minibatch step 227/1579: mean batch inertia: 42.139921875, ewa inertia: 42.057952734581676\n",
      "Minibatch step 228/1579: mean batch inertia: 42.007, ewa inertia: 42.05149954969339\n",
      "Minibatch step 229/1579: mean batch inertia: 41.991478125, ewa inertia: 42.0438978114553\n",
      "Minibatch step 230/1579: mean batch inertia: 41.992178125, ewa inertia: 42.03734749179532\n",
      "Minibatch step 231/1579: mean batch inertia: 41.9772125, ewa inertia: 42.02973137023685\n",
      "Minibatch step 232/1579: mean batch inertia: 42.2176375, ewa inertia: 42.0535297592136\n",
      "Minibatch step 233/1579: mean batch inertia: 41.87209375, ewa inertia: 42.03055081367789\n",
      "Minibatch step 234/1579: mean batch inertia: 42.038871875, ewa inertia: 42.03160467953257\n",
      "Minibatch step 235/1579: mean batch inertia: 41.866021875, ewa inertia: 42.01063354892021\n",
      "Minibatch step 236/1579: mean batch inertia: 41.98468125, ewa inertia: 42.00734667953856\n",
      "Minibatch step 237/1579: mean batch inertia: 41.974525, ewa inertia: 42.00318980026318\n",
      "Minibatch step 238/1579: mean batch inertia: 41.92159375, ewa inertia: 41.99285562678211\n",
      "Minibatch step 239/1579: mean batch inertia: 41.92473125, ewa inertia: 41.98422764631387\n",
      "Minibatch step 240/1579: mean batch inertia: 41.908234375, ewa inertia: 41.97460306710178\n",
      "Minibatch step 241/1579: mean batch inertia: 41.92951875, ewa inertia: 41.96889311971214\n",
      "Minibatch step 242/1579: mean batch inertia: 42.0438375, ewa inertia: 41.97838485644239\n",
      "Minibatch step 243/1579: mean batch inertia: 42.02140625, ewa inertia: 41.98383353371277\n",
      "Minibatch step 244/1579: mean batch inertia: 42.06295625, ewa inertia: 41.99385445842382\n",
      "Minibatch step 245/1579: mean batch inertia: 42.0876, ewa inertia: 42.005727369999825\n",
      "Minibatch step 246/1579: mean batch inertia: 42.1585, ewa inertia: 42.025076086714535\n",
      "Minibatch step 247/1579: mean batch inertia: 41.839165625, ewa inertia: 42.00153044992075\n",
      "Minibatch step 248/1579: mean batch inertia: 42.125953125, ewa inertia: 42.01728863313061\n",
      "Minibatch step 249/1579: mean batch inertia: 41.94234375, ewa inertia: 42.00779683271512\n",
      "Minibatch step 250/1579: mean batch inertia: 42.22473125, ewa inertia: 42.0352716663009\n",
      "Minibatch step 251/1579: mean batch inertia: 42.00211875, ewa inertia: 42.03107283575271\n",
      "Minibatch step 252/1579: mean batch inertia: 41.8173625, ewa inertia: 42.00400633342517\n",
      "Minibatch step 253/1579: mean batch inertia: 42.084525, ewa inertia: 42.01420405581694\n",
      "Minibatch step 254/1579: mean batch inertia: 41.733990625, ewa inertia: 41.97871490902064\n",
      "Minibatch step 255/1579: mean batch inertia: 41.927403125, ewa inertia: 41.972216250372554\n",
      "Minibatch step 256/1579: mean batch inertia: 42.097865625, ewa inertia: 41.988129795587064\n",
      "Minibatch step 257/1579: mean batch inertia: 41.90380625, ewa inertia: 41.977450183696234\n",
      "Minibatch step 258/1579: mean batch inertia: 41.93706875, ewa inertia: 41.97233585843313\n",
      "Minibatch step 259/1579: mean batch inertia: 41.9753875, ewa inertia: 41.9727223500985\n",
      "Minibatch step 260/1579: mean batch inertia: 41.825459375, ewa inertia: 41.954071433453656\n",
      "Minibatch step 261/1579: mean batch inertia: 41.9803875, ewa inertia: 41.95740437415547\n",
      "Minibatch step 262/1579: mean batch inertia: 41.91681875, ewa inertia: 41.952264188086325\n",
      "Minibatch step 263/1579: mean batch inertia: 42.038340625, ewa inertia: 41.96316580438796\n",
      "Minibatch step 264/1579: mean batch inertia: 42.0705625, ewa inertia: 41.97676764026322\n",
      "Minibatch step 265/1579: mean batch inertia: 42.029625, ewa inertia: 41.983462046714386\n",
      "Minibatch step 266/1579: mean batch inertia: 42.097059375, ewa inertia: 41.997849195279834\n",
      "Minibatch step 267/1579: mean batch inertia: 42.0769625, ewa inertia: 42.007868928012016\n",
      "Minibatch step 268/1579: mean batch inertia: 41.849496875, ewa inertia: 41.98781104205919\n",
      "Minibatch step 269/1579: mean batch inertia: 42.06074375, ewa inertia: 41.99704799965547\n",
      "Minibatch step 270/1579: mean batch inertia: 41.89594375, ewa inertia: 41.984243104660635\n",
      "Minibatch step 271/1579: mean batch inertia: 41.571228125, ewa inertia: 41.931934586830074\n",
      "Minibatch step 272/1579: mean batch inertia: 42.0174875, ewa inertia: 41.94276989863325\n",
      "Minibatch step 273/1579: mean batch inertia: 41.9492125, ewa inertia: 41.94358585675842\n",
      "Minibatch step 274/1579: mean batch inertia: 42.197690625, ewa inertia: 41.97576833065153\n",
      "Minibatch step 275/1579: mean batch inertia: 42.096984375, ewa inertia: 41.99112039275437\n",
      "Minibatch step 276/1579: mean batch inertia: 42.1623, ewa inertia: 42.01280036074293\n",
      "Minibatch step 277/1579: mean batch inertia: 41.992078125, ewa inertia: 42.01017588102373\n",
      "Minibatch step 278/1579: mean batch inertia: 42.121871875, ewa inertia: 42.02432222481327\n",
      "Minibatch step 279/1579: mean batch inertia: 42.012609375, ewa inertia: 42.02283878754471\n",
      "Minibatch step 280/1579: mean batch inertia: 42.03475625, ewa inertia: 42.02434813908893\n",
      "Minibatch step 281/1579: mean batch inertia: 41.608475, ewa inertia: 41.971677634185795\n",
      "Minibatch step 282/1579: mean batch inertia: 41.9083375, ewa inertia: 41.963655580019214\n",
      "Minibatch step 283/1579: mean batch inertia: 41.957175, ewa inertia: 41.962834811882026\n",
      "Minibatch step 284/1579: mean batch inertia: 41.933584375, ewa inertia: 41.95913023196473\n",
      "Minibatch step 285/1579: mean batch inertia: 42.148715625, ewa inertia: 41.98314130032876\n",
      "Minibatch step 286/1579: mean batch inertia: 41.966009375, ewa inertia: 41.98097153490701\n",
      "Minibatch step 287/1579: mean batch inertia: 41.892134375, ewa inertia: 41.96972027189754\n",
      "Minibatch step 288/1579: mean batch inertia: 42.1321125, ewa inertia: 41.9902873146867\n",
      "Minibatch step 289/1579: mean batch inertia: 42.01168125, ewa inertia: 41.992996865434044\n",
      "Minibatch step 290/1579: mean batch inertia: 41.76249375, ewa inertia: 41.96380355062114\n",
      "Minibatch step 291/1579: mean batch inertia: 41.9662625, ewa inertia: 41.964114977576\n",
      "Minibatch step 292/1579: mean batch inertia: 41.981603125, ewa inertia: 41.966329858673305\n",
      "Minibatch step 293/1579: mean batch inertia: 42.0395375, ewa inertia: 41.97560163669651\n",
      "Minibatch step 294/1579: mean batch inertia: 42.276934375, ewa inertia: 42.013765552512425\n",
      "Minibatch step 295/1579: mean batch inertia: 41.944540625, ewa inertia: 42.004998186839444\n",
      "Minibatch step 296/1579: mean batch inertia: 42.04735625, ewa inertia: 42.01036285304095\n",
      "Minibatch step 297/1579: mean batch inertia: 41.7702, ewa inertia: 41.979946128468754\n",
      "Minibatch step 298/1579: mean batch inertia: 42.18685625, ewa inertia: 42.00615138085532\n",
      "Minibatch step 299/1579: mean batch inertia: 42.12721875, ewa inertia: 42.02148461318217\n",
      "Minibatch step 300/1579: mean batch inertia: 41.764246875, ewa inertia: 41.98890534735155\n",
      "Minibatch step 301/1579: mean batch inertia: 42.01055, ewa inertia: 41.99164665155298\n",
      "Minibatch step 302/1579: mean batch inertia: 41.874575, ewa inertia: 41.976819478510144\n",
      "Minibatch step 303/1579: mean batch inertia: 41.853615625, ewa inertia: 41.96121565955563\n",
      "Minibatch step 304/1579: mean batch inertia: 41.827921875, ewa inertia: 41.94433394666507\n",
      "Minibatch step 305/1579: mean batch inertia: 41.8224625, ewa inertia: 41.92889887758803\n",
      "Minibatch step 306/1579: mean batch inertia: 42.1183875, ewa inertia: 41.95289768991264\n",
      "Minibatch step 307/1579: mean batch inertia: 42.00010625, ewa inertia: 41.958876673554144\n",
      "Minibatch step 308/1579: mean batch inertia: 42.129325, ewa inertia: 41.98046402452725\n",
      "Minibatch step 309/1579: mean batch inertia: 42.056203125, ewa inertia: 41.990056412897296\n",
      "Minibatch step 310/1579: mean batch inertia: 41.96315, ewa inertia: 41.98664870458621\n",
      "Minibatch step 311/1579: mean batch inertia: 42.0747875, ewa inertia: 41.99781151944405\n",
      "Minibatch step 312/1579: mean batch inertia: 41.7673625, ewa inertia: 41.96862505591062\n",
      "Minibatch step 313/1579: mean batch inertia: 41.94473125, ewa inertia: 41.96559889551919\n",
      "Minibatch step 314/1579: mean batch inertia: 41.962915625, ewa inertia: 41.96525905819922\n",
      "Minibatch step 315/1579: mean batch inertia: 42.05725, ewa inertia: 41.976909748988675\n",
      "Minibatch step 316/1579: mean batch inertia: 42.194121875, ewa inertia: 42.0044197544994\n",
      "Minibatch step 317/1579: mean batch inertia: 41.997534375, ewa inertia: 42.00354771834078\n",
      "Minibatch step 318/1579: mean batch inertia: 41.9471375, ewa inertia: 41.9964033408794\n",
      "Minibatch step 319/1579: mean batch inertia: 41.97479375, ewa inertia: 41.993666477265506\n",
      "Minibatch step 320/1579: mean batch inertia: 42.11578125, ewa inertia: 42.00913236368979\n",
      "Minibatch step 321/1579: mean batch inertia: 42.149759375, ewa inertia: 42.02694283277888\n",
      "Minibatch step 322/1579: mean batch inertia: 41.90616875, ewa inertia: 42.01164674529145\n",
      "Minibatch step 323/1579: mean batch inertia: 41.8521375, ewa inertia: 41.99144483346655\n",
      "Minibatch step 324/1579: mean batch inertia: 42.117465625, ewa inertia: 42.00740541878567\n",
      "Minibatch step 325/1579: mean batch inertia: 41.732796875, ewa inertia: 41.9726261332478\n",
      "Minibatch step 326/1579: mean batch inertia: 41.901184375, ewa inertia: 41.963578005046195\n",
      "Minibatch step 327/1579: mean batch inertia: 42.1674125, ewa inertia: 41.989393728055894\n",
      "Minibatch step 328/1579: mean batch inertia: 42.03779375, ewa inertia: 41.99552361083386\n",
      "Minibatch step 329/1579: mean batch inertia: 42.02021875, ewa inertia: 41.998651260413205\n",
      "Minibatch step 330/1579: mean batch inertia: 41.8869375, ewa inertia: 41.984502666497086\n",
      "Minibatch step 331/1579: mean batch inertia: 41.83568125, ewa inertia: 41.96565437260517\n",
      "Minibatch step 332/1579: mean batch inertia: 41.9230875, ewa inertia: 41.960263260601224\n",
      "Minibatch step 333/1579: mean batch inertia: 42.033796875, ewa inertia: 41.969576323248695\n",
      "Minibatch step 334/1579: mean batch inertia: 41.913346875, ewa inertia: 41.962454840394166\n",
      "Minibatch step 335/1579: mean batch inertia: 42.06619375, ewa inertia: 41.97559341616035\n",
      "Minibatch step 336/1579: mean batch inertia: 41.953559375, ewa inertia: 41.97280279574299\n",
      "Minibatch step 337/1579: mean batch inertia: 42.19083125, ewa inertia: 42.00041618956334\n",
      "Minibatch step 338/1579: mean batch inertia: 42.144221875, ewa inertia: 42.01862923904397\n",
      "Minibatch step 339/1579: mean batch inertia: 42.04041875, ewa inertia: 42.02138888960991\n",
      "Minibatch step 340/1579: mean batch inertia: 42.06440625, ewa inertia: 42.02683705607796\n",
      "Minibatch step 341/1579: mean batch inertia: 41.867459375, ewa inertia: 42.006651806915066\n",
      "Minibatch step 342/1579: mean batch inertia: 42.068078125, ewa inertia: 42.01443147548169\n",
      "Minibatch step 343/1579: mean batch inertia: 41.78078125, ewa inertia: 41.98483957788088\n",
      "Minibatch step 344/1579: mean batch inertia: 41.74790625, ewa inertia: 41.95483187400463\n",
      "Minibatch step 345/1579: mean batch inertia: 42.056584375, ewa inertia: 41.96771887029952\n",
      "Minibatch step 346/1579: mean batch inertia: 42.16141875, ewa inertia: 41.99225104009979\n",
      "Minibatch step 347/1579: mean batch inertia: 41.8096, ewa inertia: 41.969118210400296\n",
      "Minibatch step 348/1579: mean batch inertia: 41.94249375, ewa inertia: 41.96574621148945\n",
      "Minibatch step 349/1579: mean batch inertia: 42.060128125, ewa inertia: 41.977699719833886\n",
      "Minibatch step 350/1579: mean batch inertia: 42.197621875, ewa inertia: 42.005552951656846\n",
      "Minibatch step 351/1579: mean batch inertia: 41.740975, ewa inertia: 41.9720440447567\n",
      "Minibatch step 352/1579: mean batch inertia: 42.016996875, ewa inertia: 41.97773733928139\n",
      "Minibatch step 353/1579: mean batch inertia: 42.06949375, ewa inertia: 41.989358326612376\n",
      "Minibatch step 354/1579: mean batch inertia: 42.23298125, ewa inertia: 42.020213270523676\n",
      "Minibatch step 355/1579: mean batch inertia: 41.96545, ewa inertia: 42.013277479683836\n",
      "Minibatch step 356/1579: mean batch inertia: 41.875315625, ewa inertia: 41.995804553782705\n",
      "Minibatch step 357/1579: mean batch inertia: 41.7839375, ewa inertia: 41.9689715038783\n",
      "Minibatch step 358/1579: mean batch inertia: 42.1947, ewa inertia: 41.997560111182445\n",
      "Minibatch step 359/1579: mean batch inertia: 41.704425, ewa inertia: 41.960434428228645\n",
      "Minibatch step 360/1579: mean batch inertia: 42.0716375, ewa inertia: 41.97451834321726\n",
      "Minibatch step 361/1579: mean batch inertia: 41.98184375, ewa inertia: 41.975446109013134\n",
      "Minibatch step 362/1579: mean batch inertia: 42.023184375, ewa inertia: 41.98149218012568\n",
      "Minibatch step 363/1579: mean batch inertia: 42.09185, ewa inertia: 41.99546904361228\n",
      "Minibatch step 364/1579: mean batch inertia: 41.926053125, ewa inertia: 41.98667748883759\n",
      "Minibatch step 365/1579: mean batch inertia: 42.04345, ewa inertia: 41.99386775083454\n",
      "Minibatch step 366/1579: mean batch inertia: 41.761421875, ewa inertia: 41.964428384614166\n",
      "Minibatch step 367/1579: mean batch inertia: 42.05366875, ewa inertia: 41.975730713764136\n",
      "Minibatch step 368/1579: mean batch inertia: 42.220453125, ewa inertia: 42.006724908265724\n",
      "Minibatch step 369/1579: mean batch inertia: 41.845990625, ewa inertia: 41.986367844875204\n",
      "Minibatch step 370/1579: mean batch inertia: 42.15978125, ewa inertia: 42.00833072428816\n",
      "Minibatch step 371/1579: mean batch inertia: 41.689465625, ewa inertia: 41.96794632770922\n",
      "Minibatch step 372/1579: mean batch inertia: 42.01444375, ewa inertia: 41.97383524545494\n",
      "Minibatch step 373/1579: mean batch inertia: 41.867690625, ewa inertia: 41.96039198541569\n",
      "Minibatch step 374/1579: mean batch inertia: 41.9522125, ewa inertia: 41.95935605020805\n",
      "Minibatch step 375/1579: mean batch inertia: 42.050528125, ewa inertia: 41.97090303115248\n",
      "Minibatch step 376/1579: mean batch inertia: 41.766565625, ewa inertia: 41.94502361423167\n",
      "Minibatch step 377/1579: mean batch inertia: 42.28849375, ewa inertia: 41.988524248847554\n",
      "Minibatch step 378/1579: mean batch inertia: 41.992540625, ewa inertia: 41.98903292454681\n",
      "Minibatch step 379/1579: mean batch inertia: 42.142275, ewa inertia: 42.00844109672212\n",
      "Minibatch step 380/1579: mean batch inertia: 41.884678125, ewa inertia: 41.99276646521503\n",
      "Minibatch step 381/1579: mean batch inertia: 42.2869125, ewa inertia: 42.030020182060795\n",
      "Minibatch step 382/1579: mean batch inertia: 41.75863125, ewa inertia: 41.99564866167822\n",
      "Minibatch step 383/1579: mean batch inertia: 42.070515625, ewa inertia: 42.00513059351773\n",
      "Minibatch step 384/1579: mean batch inertia: 41.95015, ewa inertia: 41.998167278630895\n",
      "Minibatch step 385/1579: mean batch inertia: 41.97191875, ewa inertia: 41.99484289163398\n",
      "Minibatch step 386/1579: mean batch inertia: 41.810353125, ewa inertia: 41.971477186459175\n",
      "Minibatch step 387/1579: mean batch inertia: 42.0064875, ewa inertia: 41.97591125713528\n",
      "Minibatch step 388/1579: mean batch inertia: 42.09229375, ewa inertia: 41.99065114794549\n",
      "Minibatch step 389/1579: mean batch inertia: 42.1314375, ewa inertia: 42.0084817976057\n",
      "Minibatch step 390/1579: mean batch inertia: 42.053821875, ewa inertia: 42.014224137142065\n",
      "Minibatch step 391/1579: mean batch inertia: 41.937965625, ewa inertia: 42.00456596506949\n",
      "Minibatch step 392/1579: mean batch inertia: 42.168175, ewa inertia: 42.025287116946195\n",
      "Minibatch step 393/1579: mean batch inertia: 42.15785625, ewa inertia: 42.04207705242463\n",
      "Minibatch step 394/1579: mean batch inertia: 42.025684375, ewa inertia: 42.040000913055394\n",
      "Minibatch step 395/1579: mean batch inertia: 41.90575, ewa inertia: 42.02299797944486\n",
      "Minibatch step 396/1579: mean batch inertia: 41.914628125, ewa inertia: 42.009272892601324\n",
      "Minibatch step 397/1579: mean batch inertia: 41.9841875, ewa inertia: 42.00609581726316\n",
      "Minibatch step 398/1579: mean batch inertia: 41.738753125, ewa inertia: 41.972236754822845\n",
      "Minibatch step 399/1579: mean batch inertia: 41.84674375, ewa inertia: 41.95634301390871\n",
      "Minibatch step 400/1579: mean batch inertia: 41.80038125, ewa inertia: 41.93659039206674\n",
      "Minibatch step 401/1579: mean batch inertia: 42.08366875, ewa inertia: 41.95521792687132\n",
      "Minibatch step 402/1579: mean batch inertia: 41.9919625, ewa inertia: 41.95987164224081\n",
      "Minibatch step 403/1579: mean batch inertia: 41.993715625, ewa inertia: 41.9641579966415\n",
      "Minibatch step 404/1579: mean batch inertia: 42.061990625, ewa inertia: 41.97654853944725\n",
      "Minibatch step 405/1579: mean batch inertia: 41.80900625, ewa inertia: 41.95532923926079\n",
      "Converged (lack of improvement in inertia) at step 405/1579\n",
      "2026-01-22 00:23:49 | INFO | learn_kmeans | total intertia: 41.95941\n",
      "2026-01-22 00:23:49 | INFO | learn_kmeans | finished successfully\n"
     ]
    }
   ],
   "source": [
    "!python fairseq/examples/hubert/simple_kmeans/learn_kmeans.py \\\n",
    "    /home/khanh/Projects/KhoaLuan/hubert_feats \\\n",
    "    train \\\n",
    "    1 \\\n",
    "    /home/khanh/Projects/KhoaLuan/kmeans_model.joblib \\\n",
    "    100 \\\n",
    "    --percent 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56efe3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=/home/khanh/Projects/KhoaLuan/fairseq:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7c499c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/khanh/Projects/KhoaLuan'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd843223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py\", line 13, in <module>\n",
      "    from examples.textless_nlp.gslm.speech2unit.clustering.utils import (\n",
      "ModuleNotFoundError: No module named 'examples'\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH= python  examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py \\\n",
    "    --feature_type hubert \\\n",
    "    --kmeans_model_path /home/khanh/Projects/KhoaLuan/kmeans_model.joblib \\\n",
    "    --acoustic_model_path /home/khanh/Projects/KhoaLuan/hubert_base_ls960.pt \\\n",
    "    --layer 9 \\\n",
    "    --manifest_path /home/khanh/Projects/KhoaLuan/manifest_temp/train.tsv \\\n",
    "    --out_quantized_file_path /home/khanh/Projects/KhoaLuan/train.unit \\\n",
    "    --extension .wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653dc42d",
   "metadata": {},
   "source": [
    "tạo cặp valid.unt và valid.tsv cho dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tạo file valid.unit\n",
    "export PYTHONPATH=$PYTHONPATH:$(pwd)/fairseq\n",
    "\n",
    "python fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py \\\n",
    "    --feature_type hubert \\\n",
    "    --kmeans_model_path kmeans_model.joblib \\\n",
    "    --acoustic_model_path hubert_base_ls960.pt \\\n",
    "    --layer 9 \\\n",
    "    --manifest_path data-bin/valid.tsv \\\n",
    "    --out_quantized_file_path data-bin/valid.unit \\\n",
    "    --extension .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84d6931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Đảm bảo file nguồn là file gốc (Lấy từ manifest_temp cho an toàn)\n",
    "# Nếu bạn lỡ làm hỏng data-bin/valid.tsv rồi thì lệnh này sẽ khôi phục lại\n",
    "\n",
    "# 2. Lấy thư mục gốc (Dòng đầu tiên của file)\n",
    "!ROOT_DIR_VALID=$(head -n 1 data-bin/valid.tsv)\n",
    "\n",
    "# 3. Lấy nội dung audio (Bỏ dòng đầu)\n",
    "!tail -n +2 data-bin/valid.tsv > data-bin/valid_temp.tsv\n",
    "\n",
    "# 4. Tạo Header chuẩn\n",
    "!echo -e \"id\\taudio\\tn_frames\\ttgt_text\\tspeaker\" > data-bin/valid_st.tsv\n",
    "\n",
    "# 5. GHÉP FILE (Đã sửa lỗi thiếu '/' và thêm -F'\\t')\n",
    "!paste data-bin/valid_temp.tsv data-bin/valid.unit | awk -F'\\t' -v root=\"$ROOT_DIR_VALID\" '{print \"valid_\"NR\"\\t\"root\"/\"$1\"\\t\"$2\"\\t\"$3\"\\tspk1\"}' >> data-bin/valid_st.tsv\n",
    "\n",
    "# 6. Thay thế file cũ\n",
    "!mv data-bin/valid_st.tsv data-bin/valid.tsv\n",
    "\n",
    "# 7. Dọn dẹp\n",
    "!rm data-bin/valid_temp.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ba968cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Đảm bảo file nguồn là file gốc (Lấy từ manifest_temp cho an toàn)\n",
    "# Nếu bạn lỡ làm hỏng data-bin/valid.tsv rồi thì lệnh này sẽ khôi phục lại\n",
    "\n",
    "# 2. Lấy thư mục gốc (Dòng đầu tiên của file)\n",
    "!ROOT_DIR_VALID=$(head -n 1 data-bin/train.tsv)\n",
    "\n",
    "# 3. Lấy nội dung audio (Bỏ dòng đầu)\n",
    "!tail -n +2 data-bin/train.tsv > data-bin/train_temp.tsv\n",
    "\n",
    "# 4. Tạo Header chuẩn\n",
    "!echo -e \"id\\taudio\\tn_frames\\ttgt_text\\tspeaker\" > data-bin/train_st.tsv\n",
    "\n",
    "# 5. GHÉP FILE (Đã sửa lỗi thiếu '/' và thêm -F'\\t')\n",
    "!paste data-bin/train_temp.tsv data-bin/train.unit | awk -F'\\t' -v root=\"$ROOT_DIR_VALID\" '{print \"valid_\"NR\"\\t\"root\"/\"$1\"\\t\"$2\"\\t\"$3\"\\tspk1\"}' >> data-bin/valid_st.tsv\n",
    "\n",
    "# 6. Thay thế file cũ\n",
    "!mv data-bin/train_st.tsv data-bin/train.tsv\n",
    "\n",
    "# 7. Dọn dẹp\n",
    "!rm data-bin/train_temp.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2bd2018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠 Đang sửa file: data-bin/valid.tsv...\n",
      "✅ Đã sửa xong! Kiểm tra dòng đầu tiên:\n",
      "/home/khanh/Projects/KhoaLuan/my_data/dev/5154139170448018903.wav\n",
      "🛠 Đang sửa file: data-bin/train.tsv...\n",
      "✅ Đã sửa xong! Kiểm tra dòng đầu tiên:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m fix_manifest_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-bin/valid.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m, VALID_AUDIO_ROOT)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Sửa luôn tập Train cho chắc ăn\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mfix_manifest_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata-bin/train.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_AUDIO_ROOT\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 43\u001b[0m, in \u001b[0;36mfix_manifest_file\u001b[0;34m(input_file, audio_root)\u001b[0m\n\u001b[1;32m     40\u001b[0m     f\u001b[38;5;241m.\u001b[39mwritelines(new_lines)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Đã sửa xong! Kiểm tra dòng đầu tiên:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnew_lines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#  chạy bằng code \n",
    "import os\n",
    "\n",
    "# --- CẤU HÌNH ĐƯỜNG DẪN CỨNG (Sửa nếu đường dẫn máy bạn khác) ---\n",
    "# Đây là thư mục chứa file audio gốc\n",
    "TRAIN_AUDIO_ROOT = \"/home/khanh/Projects/KhoaLuan/my_data/train\"\n",
    "VALID_AUDIO_ROOT = \"/home/khanh/Projects/KhoaLuan/my_data/dev\"\n",
    "\n",
    "def fix_manifest_file(input_file, audio_root):\n",
    "    print(f\"🛠 Đang sửa file: {input_file}...\")\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"❌ Không tìm thấy file: {input_file}\")\n",
    "        return\n",
    "\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    header = lines[0] # Giữ nguyên header\n",
    "    new_lines = [header]\n",
    "    \n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) < 4: continue # Bỏ qua dòng lỗi\n",
    "\n",
    "        # parts[1] hiện tại đang là: /filename.wav hoặc filename.wav\n",
    "        filename = os.path.basename(parts[1]) \n",
    "        \n",
    "        # Tạo đường dẫn tuyệt đối chuẩn xác\n",
    "        abs_path = os.path.join(audio_root, filename)\n",
    "        \n",
    "        # Cập nhật lại cột audio\n",
    "        parts[1] = abs_path\n",
    "        \n",
    "        # Ghép lại thành dòng hoàn chỉnh\n",
    "        new_lines.append('\\t'.join(parts) + '\\n')\n",
    "\n",
    "    # Ghi đè lại file cũ\n",
    "    with open(input_file, 'w') as f:\n",
    "        f.writelines(new_lines)\n",
    "    \n",
    "    print(f\"✅ Đã sửa xong! Kiểm tra dòng đầu tiên:\")\n",
    "    print(new_lines[1].split('\\t')[1]) # In thử đường dẫn audio dòng 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Sửa tập Valid\n",
    "    fix_manifest_file('data-bin/valid.tsv', VALID_AUDIO_ROOT)\n",
    "    \n",
    "    # Sửa luôn tập Train cho chắc ăn\n",
    "    fix_manifest_file('data-bin/train.tsv', TRAIN_AUDIO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93db0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thay thế file cũ\n",
    "!mv data-bin/train_st.tsv data-bin/train.tsv\n",
    "!mv data-bin/valid_st.tsv data-bin/valid.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d4054cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 21:48:17 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 500000, 'batch_size': 2, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 500000, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=10, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=500000, batch_size=2, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=500000, batch_size_valid=2, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_transformer_s', max_epoch=50, max_update=0, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[8], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='data-bin', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=900000, max_target_positions=2048, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, decoder_attention_heads=4, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_layers=12, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.3, activation_dropout=0.3, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_transformer_s'), 'task': Namespace(no_progress_bar=False, log_interval=10, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=500000, batch_size=2, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=500000, batch_size_valid=2, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_transformer_s', max_epoch=50, max_update=0, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[8], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='data-bin', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=900000, max_target_positions=2048, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, decoder_attention_heads=4, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_layers=12, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.3, activation_dropout=0.3, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2026-01-21 21:48:17 | INFO | fairseq.tasks.speech_to_text | dictionary size (dict.txt): 104\n",
      "2026-01-21 21:48:17 | INFO | fairseq_cli.train | S2TTransformerModel(\n",
      "  (encoder): S2TTransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (subsample): Conv1dSubsampler(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "      )\n",
      "    )\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0-11): 12 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoderScriptable(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(104, 256, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (output_projection): Linear(in_features=256, out_features=104, bias=False)\n",
      "  )\n",
      ")\n",
      "2026-01-21 21:48:17 | INFO | fairseq_cli.train | task: SpeechToTextTask\n",
      "2026-01-21 21:48:17 | INFO | fairseq_cli.train | model: S2TTransformerModel\n",
      "2026-01-21 21:48:17 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
      "2026-01-21 21:48:17 | INFO | fairseq_cli.train | num. shared model params: 27,002,880 (num. trained: 27,002,880)\n",
      "2026-01-21 21:48:17 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
      "2026-01-21 21:48:17 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
      "2026-01-21 21:48:17 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': None}\n",
      "2026-01-21 21:48:17 | INFO | fairseq.data.audio.speech_to_text_dataset | 'valid' has 0.00% OOV\n",
      "2026-01-21 21:48:17 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split=\"valid\", n_samples=394, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=None, waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
      "))\n",
      "2026-01-21 21:48:18 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2026-01-21 21:48:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2026-01-21 21:48:18 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 3.631 GB ; name = NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2026-01-21 21:48:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2026-01-21 21:48:18 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2026-01-21 21:48:18 | INFO | fairseq_cli.train | max tokens per device = 500000 and max sentences per device = 2\n",
      "2026-01-21 21:48:18 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
      "2026-01-21 21:48:18 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
      "2026-01-21 21:48:18 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2026-01-21 21:48:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
      "2026-01-21 21:48:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': None}\n",
      "2026-01-21 21:48:18 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV\n",
      "2026-01-21 21:48:18 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split=\"train\", n_samples=2_994, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=None, waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
      "))\n",
      "2026-01-21 21:48:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2026-01-21 21:48:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
      "2026-01-21 21:48:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
      "2026-01-21 21:48:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
      "2026-01-21 21:48:18 | WARNING | fairseq.tasks.fairseq_task | 3 samples have invalid sizes and will be skipped, max_positions=(500000, 2048), first few sample ids=[2076, 307, 2468]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/miniconda3/envs/hubert/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/train.py\", line 574, in cli_main\n",
      "    distributed_utils.call_main(cfg, main)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
      "    main(cfg, **kwargs)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq_cli/train.py\", line 165, in main\n",
      "    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/checkpoint_utils.py\", line 297, in load_checkpoint\n",
      "    epoch_itr = trainer.get_train_iterator(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/trainer.py\", line 736, in get_train_iterator\n",
      "    self.reset_dummy_batch(batch_iterator.first_batch)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/iterators.py\", line 372, in first_batch\n",
      "    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/iterators.py\", line 372, in <listcomp>\n",
      "    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/audio/speech_to_text_dataset.py\", line 261, in __getitem__\n",
      "    source = self._get_source_audio(indices if has_concat else index)\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/audio/speech_to_text_dataset.py\", line 226, in _get_source_audio\n",
      "    source = get_features_or_waveform(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/audio/audio_utils.py\", line 188, in get_features_or_waveform\n",
      "    return get_waveform(\n",
      "  File \"/home/khanh/Projects/KhoaLuan/fairseq/fairseq/data/audio/audio_utils.py\", line 105, in get_waveform\n",
      "    waveform, sample_rate = sf.read(\n",
      "  File \"/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/soundfile.py\", line 305, in read\n",
      "    with SoundFile(file, 'r', samplerate, channels,\n",
      "  File \"/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/soundfile.py\", line 690, in __init__\n",
      "    self._file = self._open(file, mode_int, closefd)\n",
      "  File \"/home/khanh/miniconda3/envs/hubert/lib/python3.10/site-packages/soundfile.py\", line 1265, in _open\n",
      "    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\n",
      "soundfile.LibsndfileError: Error opening '2080262898138207829.wav': System error.\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data-bin \\\n",
    "    --config-yaml config.yaml \\\n",
    "    --task speech_to_text \\\n",
    "    --arch s2t_transformer_s \\\n",
    "    --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 10.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 500000 \\\n",
    "    --batch-size 2 \\\n",
    "    --update-freq 8 \\\n",
    "    --max-epoch 50 \\\n",
    "    --save-dir checkpoints \\\n",
    "    --log-format json --log-interval 10 \\\n",
    "    --fp16 \\\n",
    "    --max-source-positions 900000 \\\n",
    "    --max-target-positions 2048 \\\n",
    "    --skip-invalid-size-inputs-valid-test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
